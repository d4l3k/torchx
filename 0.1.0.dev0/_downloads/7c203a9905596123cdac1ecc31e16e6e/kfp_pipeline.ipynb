{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# KubeFlow Pipelines Example\n\nThis is an example pipeline using KubeFlow Pipelines built with only TorchX\ncomponents.\n\nKFP adapters can be used transform the TorchX components directly into\nsomething that can be used within KFP.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input Arguments\nLets first define some arguments for the pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\n\nparser = argparse.ArgumentParser(description=\"example kfp pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TorchX components are built around images. Depending on what scheduler\nyou're using this can vary but for KFP these images are specified as\ndocker containers. We have one container for the example apps and one for\nthe standard built in apps. If you modify the torchx example code you'll\nneed to rebuild the container before launching it on KFP\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser.add_argument(\n    \"--image\",\n    type=str,\n    help=\"docker image to use\",\n    default=\"495572122715.dkr.ecr.us-west-2.amazonaws.com/torchx/examples:latest\",\n)\nparser.add_argument(\n    \"--torchx_image\",\n    type=str,\n    help=\"docker image to use\",\n    default=\"495572122715.dkr.ecr.us-west-2.amazonaws.com/torchx:latest\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most TorchX compnents use\n`fsspec <https://filesystem-spec.readthedocs.io/en/latest/>`_ to abstract\naway dealing with remote filesystems. This allows the components to take\npaths like `s3://` to make it easy to use cloud storage providers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser.add_argument(\n    \"--data_path\",\n    type=str,\n    help=\"path to place the data\",\n    required=True,\n)\nparser.add_argument(\"--load_path\", type=str, help=\"checkpoint path to load from\")\nparser.add_argument(\n    \"--output_path\",\n    type=str,\n    help=\"path to place checkpoints and model outputs\",\n    required=True,\n)\nparser.add_argument(\n    \"--log_dir\", type=str, help=\"directory to place the logs\", default=\"/tmp\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example uses the torchserve for inference so we need to specify some\noptions. This assumes you have a TorchServe instance running in the same\nKubernetes cluster with with the service name `torchserve` in the default\nnamespace.\n\nSee https://github.com/pytorch/serve/blob/master/kubernetes/README.md for info\non how to setup TorchServe.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser.add_argument(\n    \"--management_api\",\n    type=str,\n    help=\"path to the torchserve management API\",\n    default=\"http://torchserve.default.svc.cluster.local:8081\",\n)\nparser.add_argument(\n    \"--model_name\",\n    type=str,\n    help=\"the name of the inference model\",\n    default=\"tiny_image_net\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, set the output path for the exported KFP pipeline package. This can either be\n.yaml or .zip.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser.add_argument(\n    \"--package_path\",\n    type=str,\n    help=\"path to place the compiled pipeline package\",\n    default=\"pipeline.yaml\",\n)\n\nimport sys\n\nargs: argparse.Namespace = parser.parse_args(sys.argv[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the Components\nThe first component we're creating is a data preprocessor. TorchX\nseparates the definitions (component) from the implementation (app) so in our\npipeline we just need to define a simple component so TorchX knows how to\nexecute the datapreproc app.\n\ndatapreproc outputs the data to a specified fsspec path. These paths are all\nspecified ahead of time so we have a fully static pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchx import specs\nfrom torchx.components.base.binary_component import binary_component\n\ndatapreproc_app: specs.AppDef = binary_component(\n    name=\"examples-datapreproc\",\n    entrypoint=\"datapreproc/datapreproc.py\",\n    args=[\n        \"--output_path\",\n        args.data_path,\n    ],\n    image=args.image,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the TorchX component we need to adapt it so it can run in KFP\nvia our KFP adapter. component_from_app takes in a TorchX component and\nreturns a KFP component.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchx.pipelines.kfp.adapter import ContainerFactory, component_from_app\n\ndatapreproc_comp: ContainerFactory = component_from_app(datapreproc_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll create the trainer component that takes in the training data from the\nprevious datapreproc component.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer_app: specs.AppDef = binary_component(\n    name=\"examples-lightning_classy_vision-trainer\",\n    entrypoint=\"lightning_classy_vision/main.py\",\n    args=[\n        \"--output_path\",\n        args.output_path,\n        \"--load_path\",\n        args.load_path or \"\",\n        \"--log_dir\",\n        args.log_dir,\n        \"--data_path\",\n        args.data_path,\n    ],\n    image=args.image,\n)\ntrainer_comp: ContainerFactory = component_from_app(trainer_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the inference, we're leveraging one of the builtin TorchX components. This\ncomponent takes in a model and uploads it to the TorchServe management API\nendpoints.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path\n\nfrom torchx.components.serve.serve import torchserve\n\nserve_app: specs.AppDef = torchserve(\n    model_path=os.path.join(args.output_path, \"model.mar\"),\n    management_api=args.management_api,\n    image=args.torchx_image,\n    params={\n        \"model_name\": args.model_name,\n        # set this to allocate a worker\n        # \"initial_workers\": 1,\n    },\n)\nserve_comp: ContainerFactory = component_from_app(serve_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Definition\nThe last step is to define the actual pipeline using the adapted KFP\ncomponents and export the pipeline package that can be uploaded to a KFP\ncluster.\n\nThe KFP adapter currently doesn't track the input and outputs so the\ncontainers need to have their dependencies specified via `.after()`.\n\nWe call `.set_tty()` to make the logs from the components more responsive for\nexample purposes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import kfp\n\n\ndef pipeline() -> None:\n    datapreproc = datapreproc_comp()\n    datapreproc.container.set_tty()\n\n    trainer = trainer_comp()\n    trainer.container.set_tty()\n    trainer.after(datapreproc)\n\n    serve = serve_comp()\n    serve.container.set_tty()\n    serve.after(trainer)\n\n\nkfp.compiler.Compiler().compile(\n    pipeline_func=pipeline,\n    package_path=args.package_path,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once this has all run you should have a pipeline file (typically\npipeline.yaml) that you can upload to your KFP cluster via the UI or\na kfp.Client.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}