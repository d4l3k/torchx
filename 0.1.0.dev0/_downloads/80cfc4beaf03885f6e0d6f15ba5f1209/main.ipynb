{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Trainer App Example\n\nThis is an example TorchX app that uses PyTorch Lightning and ClassyVision to\ntrain a model.\n\nThis app only uses standard OSS libraries and has no runtime torchx\ndependencies. For saving and loading data and models it uses fsspec which makes\nthe app agnostic to the environment it's running in.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\nimport os.path\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nfrom typing import List\n\nimport fsspec\nimport pytorch_lightning as pl\nimport torch\nimport torch.jit\nfrom classy_vision.dataset.classy_dataset import ClassyDataset\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n\nclass TinyImageNetDataset(ClassyDataset):\n    def __init__(self, data_path, transform):\n        batchsize_per_replica = 16\n        shuffle = False\n        num_samples = 1000\n        dataset = datasets.ImageFolder(data_path)\n        super().__init__(\n            dataset, batchsize_per_replica, shuffle, transform, num_samples\n        )\n\n\nclass TinyImageNetModel(pl.LightningModule):\n    \"\"\"\n    An very simple linear model for the tiny image net dataset.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(64 * 64, 4096)\n\n    def forward(self, x):\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        loss = F.cross_entropy(self(x), y)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.02)\n\n\ndef parse_args(argv: List[str]) -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"pytorch lightning + classy vision TorchX example app\"\n    )\n    parser.add_argument(\n        \"--epochs\", type=int, default=3, help=\"number of epochs to train\"\n    )\n    parser.add_argument(\n        \"--batch_size\", type=int, default=32, help=\"batch size to use for training\"\n    )\n    parser.add_argument(\n        \"--data_path\",\n        type=str,\n        help=\"path to load the training data from\",\n        required=True,\n    )\n    parser.add_argument(\"--load_path\", type=str, help=\"checkpoint path to load from\")\n    parser.add_argument(\n        \"--output_path\",\n        type=str,\n        help=\"path to place checkpoints and model outputs\",\n        required=True,\n    )\n    parser.add_argument(\n        \"--log_dir\", type=str, help=\"directory to place the logs\", default=\"/tmp\"\n    )\n\n    return parser.parse_args(argv)\n\n\ndef download_data(remote_path: str, tmpdir: str) -> str:\n    tar_path = os.path.join(tmpdir, \"data.tar.gz\")\n    print(f\"downloading dataset from {remote_path} to {tar_path}...\")\n    fs, _, rpaths = fsspec.get_fs_token_paths(remote_path)\n    assert len(rpaths) == 1, \"must have single path\"\n    fs.get(rpaths[0], tar_path)\n\n    data_path = os.path.join(tmpdir, \"data\")\n    print(f\"extracting {tar_path} to {data_path}...\")\n    with tarfile.open(tar_path, mode=\"r\") as f:\n        f.extractall(data_path)\n\n    return data_path\n\n\ndef export_inference_model(\n    model: TinyImageNetModel, out_path: str, tmpdir: str\n) -> None:\n    print(\"exporting inference model\")\n    jit_path = os.path.join(tmpdir, \"model_jit.pt\")\n    jitted = torch.jit.script(model)\n    print(f\"saving JIT model to {jit_path}\")\n    torch.jit.save(jitted, jit_path)\n\n    model_name = \"tiny_image_net\"\n\n    mar_path = os.path.join(tmpdir, f\"{model_name}.mar\")\n    print(f\"creating model archive at {mar_path}\")\n    subprocess.run(\n        [\n            \"torch-model-archiver\",\n            \"--model-name\",\n            \"tiny_image_net\",\n            \"--handler\",\n            \"lightning_classy_vision/handler/handler.py\",\n            \"--version\",\n            \"1\",\n            \"--serialized-file\",\n            jit_path,\n            \"--export-path\",\n            tmpdir,\n        ],\n        check=True,\n    )\n\n    remote_path = os.path.join(out_path, \"model.mar\")\n    print(f\"uploading to {remote_path}\")\n    fs, _, rpaths = fsspec.get_fs_token_paths(remote_path)\n    assert len(rpaths) == 1, \"must have single path\"\n    fs.put(mar_path, rpaths[0])\n\n\ndef main(argv):\n    with tempfile.TemporaryDirectory() as tmpdir:\n        args = parse_args(argv)\n\n        # Init our model\n        model = TinyImageNetModel()\n\n        data_path = download_data(args.data_path, tmpdir)\n\n        # Setup data loader and transforms\n        img_transform = transforms.Compose(\n            [\n                transforms.Grayscale(),\n                transforms.ToTensor(),\n            ]\n        )\n        train_ds = TinyImageNetDataset(\n            data_path=os.path.join(data_path, \"train\"),\n            transform=lambda x: (img_transform(x[0]), x[1]),\n        )\n        train_loader = DataLoader(train_ds, batch_size=args.batch_size)\n\n        checkpoint_callback = ModelCheckpoint(\n            monitor=\"train_loss\",\n            dirpath=args.output_path,\n            save_last=True,\n        )\n        if args.load_path:\n            print(f\"loading checkpoint: {args.load_path}...\")\n            mnist_model.load_from_checkpoint(checkpoint_path=args.load_path)\n\n        logger = TensorBoardLogger(\n            save_dir=args.log_dir, version=1, name=\"lightning_logs\"\n        )\n\n        # Initialize a trainer\n        trainer = pl.Trainer(\n            logger=logger,\n            max_epochs=args.epochs,\n            callbacks=[checkpoint_callback],\n        )\n\n        # Train the model \u26a1\n        trainer.fit(model, train_loader)\n\n        export_inference_model(model, args.output_path, tmpdir)\n\n\nif __name__ == \"__main__\":\n    main(sys.argv[1:])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}